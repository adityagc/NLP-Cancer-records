{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "from os import listdir\n",
    "import sys\n",
    "import re\n",
    "import operator\n",
    "import random\n",
    "import time\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = (\"/Users/patrickmcneillie/data_hub/naccr\")\n",
    "out_dir = (\"/Users/patrickmcneillie/data_hub/naccr\")\n",
    "\n",
    "path_to_data_directory = (\"/Users/patrickmcneillie/data_hub/naccr/text_file_v3\")\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_csv_file_comma(csv_file_path):\n",
    "    with open(csv_file_path, 'r', encoding='ISO-8859-1') as infile:\n",
    "        data_reader = csv.reader(infile, delimiter=',', quotechar='\"')\n",
    "        data_list_object = list(data_reader)\n",
    "    return data_list_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv_file_rows(rows, process_file):\n",
    "    with codecs.open(process_file, encoding='utf-8', mode='w') as fulltext_file:\n",
    "        writer = csv.writer(fulltext_file, quoting=csv.QUOTE_ALL)\n",
    "        writer.writerows(rows)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_text_file(lines, process_file):\n",
    "    with codecs.open(process_file, encoding='utf-8', mode='w') as out:\n",
    "        for row in lines:\n",
    "            out.write(row + '\\n')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_text_file_add(lines, process_file):\n",
    "    with codecs.open(process_file, encoding='utf-8', mode='a+') as out:\n",
    "        for row in lines:\n",
    "            out.write(row + '\\n')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_cleaning(string):\n",
    "##add padding to other punctuation\n",
    "    string = re.sub(r'\"', '', string)\n",
    "    string = re.sub(r'(_+)', '_', string)\n",
    "    string = re.sub(r'(\\.+)', '.', string)\n",
    "    string = re.sub(r',', ' , ', string)\n",
    "    string = re.sub(r'\\\\X0D\\\\\\\\X0A\\\\', '\\n\\r', string)\n",
    "    string = re.sub(r'(\\d)(\\s|)(x)(\\s|)(\\d)', r'\\1 \\3 \\5', string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    \n",
    "    return string;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def section_labeling(all_headers, inscope_headers, inscope_index, row, x1):\n",
    "    \n",
    "    #global new_file_list\n",
    "    new_file_list = []\n",
    "    noun_phase_chunk = []\n",
    "    \n",
    "    for indx in inscope_index:\n",
    "        \n",
    "        focus = row[indx]\n",
    "\n",
    "        if all_headers[indx] == 'PATIENT_DISPLAY_ID':\n",
    "            new_file_list.append(\"Patient_ID :\")\n",
    "            new_file_list.append(focus)\n",
    "            pt_id = focus\n",
    "        elif all_headers[indx] == 'SITE':\n",
    "            new_file_list.append(\"SITE_ID :\")\n",
    "            new_file_list.append(focus)\n",
    "            site_id = focus\n",
    "        else:\n",
    "            item = all_headers[indx]\n",
    "            if 'TEXT_PATH_' in item:\n",
    "                item = re.sub(r'TEXT_PATH_', '', item)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            sect_id = (\"%s :\" % (item))\n",
    "            new_file_list.append(sect_id)\n",
    "            focus_new = string_cleaning(focus)\n",
    "            doc = nlp(focus_new)\n",
    "            for sent in doc.sents:\n",
    "                new_file_list.append(sent.text)\n",
    "                doc2 = nlp(sent.text)\n",
    "                for chunk in doc2.noun_chunks:\n",
    "                    noun_phase_chunk.append(chunk.text)\n",
    "            \n",
    "    file_id = (site_id + \"_\" + pt_id + \"_\" + str(x1))\n",
    "    new_file_name = (\"%s/%s.txt\" % (path_to_data_directory, file_id))\n",
    "    save_text_file(new_file_list, new_file_name)\n",
    "    noun_phase_file = (\"/Users/patrickmcneillie/data_hub/naccr/noun_phase_v1.txt\")\n",
    "    save_text_file_add(noun_phase_chunk, noun_phase_file)\n",
    "    \n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete\n"
     ]
    }
   ],
   "source": [
    "current_file = ('%s/%s' % (root_dir, 'train.csv'))\n",
    "rows_data = open_csv_file_comma(current_file)\n",
    "\n",
    "\n",
    "all_headers = rows_data[0]\n",
    "inscope_headers = ['SITE', 'PATIENT_DISPLAY_ID', 'TEXT_PATH_CLINICAL_HISTORY', 'TEXT_PATH_COMMENTS', 'TEXT_PATH_FORMAL_DX', 'TEXT_PATH_FULL_TEXT', 'TEXT_PATH_GROSS_PATHOLOGY', 'TEXT_PATH_MICROSCOPIC_DESC', 'TEXT_PATH_NATURE_OF_SPECIMENS', 'TEXT_PATH_STAGING_PARAMS', 'TEXT_PATH_SUPP_REPORTS_ADDENDA']\n",
    "inscope_index = []\n",
    "for head in inscope_headers:\n",
    "    indexy = all_headers.index(head)\n",
    "    inscope_index.append(indexy)\n",
    "\n",
    "\n",
    "x1 = 1\n",
    "while x1 < len(rows_data):\n",
    "\n",
    "    row = rows_data[x1]\n",
    "    section_labeling(all_headers, inscope_headers, inscope_index, row, x1)\n",
    "    \n",
    "    x1 = x1 + 1\n",
    "\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sections():\n",
    "\n",
    "    line2 = line.lstrip()\n",
    "    if re.match(r'((history/chief complaint|procedure|operative report|pathology report|vital signs|vs|general|heent|head/neck|eyes|ent|neck|lymph nodes|ln|nodes|cardiovascular|cardiac|chest|heart|respiratory|lungs|dermatology|derm|skin|integument|integ|breast|breasts|breast/chest|abdomen|abd|gastrointestional|gi|genitourinary|gu|rectal|pelvic|rectal/pelvic|musculoskeletal|msk|ms|extremities|estremities|vascular|neurologic|neurological|neuro|psychiatric|psych|endocrine|hematologic|heme|data review|pertinent diagnostic tests|genetics|radiology|radiology review|imaging|pathology|pathology is as follows|addendum|add|attending addendum|attending note |attending note|attending summary|attending summary/addendum|social history|associated medical conditions|routine health maintenance|review of systems|reason for consultation|reason for consult|reason for referral|reason for visit|plan|plan/discussion|physical examination|past surgical history|past medical history|past medical problems|pmh|past medical and surgical history|past medical/surgical history|cancer history|other medical conditions|other surgeries|obstetrical/gynecologic|ob/gyn|obstetric history|past oby-gyn history|past obstetrical/gynecological history|ob|ob history|past gynecologic history|past gyn history|past gyne history|gynecology|gyn history|gyn/menstrual history|gyn|gynecologic history|gynecological history|gynecology history|note|medical problems|impression/plan|impression|imrpession|history of present illness|history|healthcare maintenance|health care maintenance|health care management|health maintenance|chief complaint|chief complaint/identifying data|identifying data|discussion and plan|discussion/plan|discussion|diagnosis|family history|screening history|age appropriate cancer screening|age appropriate screening|cancer screening|medications|home medications|allergies|current medications)(:|\\n|\\r))', line2, flags= re.I):\n",
    "        johns = re.match(r'((history/chief complaint|procedure|operative report|pathology report|vital signs|vs|general|heent|head/neck|eyes|ent|neck|lymph nodes|ln|nodes|cardiovascular|cardiac|chest|heart|respiratory|lungs|dermatology|derm|skin|integument|integ|breast|breasts|breast/chest|abdomen|abd|gastrointestional|gi|genitourinary|gu|rectal|pelvic|rectal/pelvic|musculoskeletal|msk|ms|extremities|estremities|vascular|neurologic|neurological|neuro|psychiatric|psych|endocrine|hematologic|heme|data review|pertinent diagnostic tests|genetics|radiology|radiology review|imaging|pathology|pathology is as follows|addendum|add|attending addendum|attending note |attending note|attending summary|attending summary/addendum|social history|associated medical conditions|routine health maintenance|review of systems|reason for consultation|reason for consult|reason for referral|reason for visit|plan|plan/discussion|physical examination|past surgical history|past medical history|past medical problems|pmh|past medical and surgical history|past medical/surgical history|cancer history|other medical conditions|other surgeries|obstetrical/gynecologic|ob/gyn|obstetric history|past oby-gyn history|past obstetrical/gynecological history|ob|ob history|past gynecologic history|past gyn history|past gyne history|gynecology|gyn history|gyn/menstrual history|gyn|gynecologic history|gynecological history|gynecology history|note|medical problems|impression/plan|impression|imrpession|history of present illness|history|healthcare maintenance|health care maintenance|health care management|health maintenance|chief complaint|chief complaint/identifying data|identifying data|discussion and plan|discussion/plan|discussion|diagnosis|family history|screening history|age appropriate cancer screening|age appropriate screening|cancer screening|medications|home medications|allergies|current medications)(:|\\n|\\r))', line2, flags= re.I)\n",
    "        jimmy = johns.group(0)\n",
    "\n",
    "        listy1.append(i)\n",
    "        listy2.append(jimmy)\n",
    "        section_set.add(jimmy)\n",
    "    \n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Final Diagnosis 1'\n",
    "'Gross Description 1'\n",
    "'Sections are submitted as follows'\n",
    "'1A , 1B:'\n",
    "'1C through 1F'\n",
    "'1G , 1H'\n",
    "'1I , 1J'\n",
    "'2A.'\n",
    "'Procedures/Addenda SUPPLEMENTAL REPORT Date Ordered'\n",
    "'Status'\n",
    "'Signed Out Date Complete'\n",
    "'by'\n",
    "'Date Reported'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_save(lines_final,outfile):\n",
    "    global my_dict\n",
    "    with codecs.open(outfile, 'w', encoding='utf-8') as out:\n",
    "        full_text = ' '.join(lines_final)\n",
    "        out.write(full_text)\n",
    "\n",
    "    return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_dictionary(line):\n",
    "    global my_dict\n",
    "\n",
    "    line_d = re.sub(r'(\\.)(\\s)', ' ', line)\n",
    "    line_toks = line_d.split()\n",
    "    \n",
    "    for word in line_toks:\n",
    "        if word in my_dict.keys():\n",
    "            my_dict[word] = my_dict[word] + 1\n",
    "        else:\n",
    "            my_dict[word] = 1\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = ['bc_cleaned_1']\n",
    "output = 'bc_genia'\n",
    "\n",
    "my_dict = dict()\n",
    "section_set = set()\n",
    "first_section = []\n",
    "last_section = []\n",
    "\n",
    "for directory in dir_list:\n",
    "    source_dir = (\"%s/%s\" % (root_dir, directory))\n",
    "    process_dir = (\"%s/%s\" % (out_dir, output))\n",
    "\n",
    "    docset = listdir(source_dir)\n",
    "    \n",
    "    print('Current Directory: %s processing.......' % directory)\n",
    "\n",
    "    x1 = 0\n",
    "    while x1 < len(docset):\n",
    "        doc = docset[x1]\n",
    "        infile = (\"%s/%s\" % (source_dir, doc))\n",
    "        outfile = (\"%s/%s\" % (process_dir, doc))\n",
    "        data = codecs.open(infile, 'r', encoding='utf-8')\n",
    "        stringy = data.readlines()\n",
    "        data.close()\n",
    "        \n",
    "        listy1 = []\n",
    "        listy2 = []\n",
    "        final_out = []\n",
    "        restringy = []\n",
    "\n",
    "        for i, line in enumerate(stringy):\n",
    "\n",
    "            line2 = line.lstrip()\n",
    "            if re.match(r'((history/chief complaint|procedure|operative report|pathology report|vital signs|vs|general|heent|head/neck|eyes|ent|neck|lymph nodes|ln|nodes|cardiovascular|cardiac|chest|heart|respiratory|lungs|dermatology|derm|skin|integument|integ|breast|breasts|breast/chest|abdomen|abd|gastrointestional|gi|genitourinary|gu|rectal|pelvic|rectal/pelvic|musculoskeletal|msk|ms|extremities|estremities|vascular|neurologic|neurological|neuro|psychiatric|psych|endocrine|hematologic|heme|data review|pertinent diagnostic tests|genetics|radiology|radiology review|imaging|pathology|pathology is as follows|addendum|add|attending addendum|attending note |attending note|attending summary|attending summary/addendum|social history|associated medical conditions|routine health maintenance|review of systems|reason for consultation|reason for consult|reason for referral|reason for visit|plan|plan/discussion|physical examination|past surgical history|past medical history|past medical problems|pmh|past medical and surgical history|past medical/surgical history|cancer history|other medical conditions|other surgeries|obstetrical/gynecologic|ob/gyn|obstetric history|past oby-gyn history|past obstetrical/gynecological history|ob|ob history|past gynecologic history|past gyn history|past gyne history|gynecology|gyn history|gyn/menstrual history|gyn|gynecologic history|gynecological history|gynecology history|note|medical problems|impression/plan|impression|imrpession|history of present illness|history|healthcare maintenance|health care maintenance|health care management|health maintenance|chief complaint|chief complaint/identifying data|identifying data|discussion and plan|discussion/plan|discussion|diagnosis|family history|screening history|age appropriate cancer screening|age appropriate screening|cancer screening|medications|home medications|allergies|current medications)(:|\\n|\\r))', line2, flags= re.I):\n",
    "                johns = re.match(r'((history/chief complaint|procedure|operative report|pathology report|vital signs|vs|general|heent|head/neck|eyes|ent|neck|lymph nodes|ln|nodes|cardiovascular|cardiac|chest|heart|respiratory|lungs|dermatology|derm|skin|integument|integ|breast|breasts|breast/chest|abdomen|abd|gastrointestional|gi|genitourinary|gu|rectal|pelvic|rectal/pelvic|musculoskeletal|msk|ms|extremities|estremities|vascular|neurologic|neurological|neuro|psychiatric|psych|endocrine|hematologic|heme|data review|pertinent diagnostic tests|genetics|radiology|radiology review|imaging|pathology|pathology is as follows|addendum|add|attending addendum|attending note |attending note|attending summary|attending summary/addendum|social history|associated medical conditions|routine health maintenance|review of systems|reason for consultation|reason for consult|reason for referral|reason for visit|plan|plan/discussion|physical examination|past surgical history|past medical history|past medical problems|pmh|past medical and surgical history|past medical/surgical history|cancer history|other medical conditions|other surgeries|obstetrical/gynecologic|ob/gyn|obstetric history|past oby-gyn history|past obstetrical/gynecological history|ob|ob history|past gynecologic history|past gyn history|past gyne history|gynecology|gyn history|gyn/menstrual history|gyn|gynecologic history|gynecological history|gynecology history|note|medical problems|impression/plan|impression|imrpession|history of present illness|history|healthcare maintenance|health care maintenance|health care management|health maintenance|chief complaint|chief complaint/identifying data|identifying data|discussion and plan|discussion/plan|discussion|diagnosis|family history|screening history|age appropriate cancer screening|age appropriate screening|cancer screening|medications|home medications|allergies|current medications)(:|\\n|\\r))', line2, flags= re.I)\n",
    "                jimmy = johns.group(0)\n",
    "\n",
    "                listy1.append(i)\n",
    "                listy2.append(jimmy)\n",
    "                section_set.add(jimmy)\n",
    "\n",
    "            restringy.append(line)\n",
    "\n",
    "\n",
    "        for x2 in range(len(listy1)):\n",
    "\n",
    "            if x2 == 0 and (len(listy1) == 0):\n",
    "                section0 = restringy\n",
    "                for liney in section0:\n",
    "                    liney2 = liney.lstrip()\n",
    "                    if liney2 != '':\n",
    "                        liney2 = re.sub(r'\\n|\\r', ' ', liney2)\n",
    "                        liney2 = re.sub(r\"\\s{2,}\", \" \", liney2)\n",
    "                        final_out.append(liney2)\n",
    "\n",
    "            elif x2 == 0 and (len(listy1) == 1):\n",
    "\n",
    "                section1 = restringy[:listy1[x2]]\n",
    "                for liney in section1:\n",
    "                    liney2 = liney.lstrip()\n",
    "                    if liney2 != '':\n",
    "                        liney2 = re.sub(r'\\n|\\r', ' ', liney2)\n",
    "                        liney2 = re.sub(r\"\\s{2,}\", \" \", liney2)\n",
    "                        final_out.append(liney2)\n",
    "\n",
    "                section2_title = re.sub(r'\\n|\\r', '', listy2[x2])\n",
    "                section2_title_new = ('\\n===SECTION: %s===\\n' % (section2_title))\n",
    "                final_out.append(section2_title_new)\n",
    "                section2 = restringy[listy1[x2]:]\n",
    "                for liney0 in section2:\n",
    "                    liney = liney0.lstrip()\n",
    "                    liney1 = liney.replace(section2_title, '')\n",
    "                    liney2 = liney1.lstrip()\n",
    "                    if liney2 != '':\n",
    "                        liney2 = re.sub(r'\\n|\\r', ' ', liney2)\n",
    "                        liney2 = re.sub(r\"\\s{2,}\", \" \", liney2)\n",
    "                        final_out.append(liney2)\n",
    "\n",
    "            elif x2 == 0 and (len(listy1) > 1):\n",
    "\n",
    "                section1 = restringy[:listy1[x2]]\n",
    "                #######DELETE##########\n",
    "                document_name = (doc + '\\n')\n",
    "                first_section.append(document_name)\n",
    "                firsty = []\n",
    "                #######DELETE##########\n",
    "                for liney in section1:\n",
    "                    liney2 = liney.lstrip()\n",
    "                    if liney2 != '':\n",
    "                        liney2 = re.sub(r'\\n|\\r', ' ', liney2)\n",
    "                        liney2 = re.sub(r\"\\s{2,}\", \" \", liney2)\n",
    "                        ########final_out.append(liney2)\n",
    "                        firsty.append(liney2)\n",
    "                \n",
    "                first_out = ' '.join(firsty)\n",
    "                first_out2 = re.sub(r\"\\s{2,}\", \" \", first_out)\n",
    "                first_section.append(first_out2 + '\\n')\n",
    "\n",
    "                section2_title = re.sub(r'\\n|\\r', '', listy2[x2])\n",
    "                section2_title_new = ('\\n===SECTION: %s===\\n' % (section2_title))\n",
    "                final_out.append(section2_title_new)\n",
    "                section2 = restringy[listy1[x2]:listy1[x2+1]]\n",
    "                for liney0 in section2:\n",
    "                    liney = liney0.lstrip()\n",
    "                    liney1 = liney.replace(section2_title, '')\n",
    "                    liney2 = liney1.lstrip()\n",
    "                    if liney2 != '':\n",
    "                        liney2 = re.sub(r'\\n|\\r', ' ', liney2)\n",
    "                        liney2 = re.sub(r\"\\s{2,}\", \" \", liney2)\n",
    "                        final_out.append(liney2)\n",
    "\n",
    "\n",
    "            elif x2 == (len(listy1)-1):\n",
    "\n",
    "                section_final_title = re.sub(r'\\n|\\r', '', listy2[x2])\n",
    "                section_final_title_new = ('\\n===SECTION: %s===\\n' % (section_final_title))\n",
    "                final_out.append(section_final_title_new)\n",
    "                section_final = restringy[listy1[x2]:]\n",
    "                #######DELETE##########\n",
    "                document_name = (doc + '\\n')\n",
    "                last_section.append(document_name)\n",
    "                lasty = []\n",
    "                #######DELETE##########\n",
    "                for liney0 in section_final:\n",
    "                    liney = liney0.lstrip()\n",
    "                    liney1 = liney.replace(section_final_title, '')\n",
    "                    liney2 = liney1.lstrip()\n",
    "                    if liney2 != '':\n",
    "                        liney2 = re.sub(r'\\n|\\r', ' ', liney2)\n",
    "                        liney2 = re.sub(r\"\\s{2,}\", \" \", liney2)\n",
    "                        #########final_out.append(liney2)\n",
    "                        lasty.append(liney2)\n",
    "                \n",
    "                last_out = ' '.join(lasty)\n",
    "                last_out2 = re.sub(r\"\\s{2,}\", \" \", last_out)\n",
    "                really_last = []               \n",
    "                if re.search(r'(DICT:)(.*)', last_out2, flags= re.I):\n",
    "                    s = re.search(r'(DICT:)(.*)', last_out2, flags= re.I)\n",
    "                    last_section.append(s.group(0) + '\\n')\n",
    "                    liney3 = last_out2.replace(s.group(0), '')\n",
    "                    final_out.append(liney3)\n",
    "                    \n",
    "                elif re.search(r'(INTERNAL CC:)|(Fax Request Sent to Server for:)|(Report Electronically Signed Out by)|(EXTERNAL CC:)|(\\(\\*\\*\\[MD Initials\\]\\) cc:)', last_out2, flags= re.I):                   \n",
    "                    if re.search(r'(INTERNAL CC:)', last_out2, flags= re.I):\n",
    "                        s1 = re.search(r'(INTERNAL CC:)(.*)', last_out2, flags= re.I)\n",
    "                        really_last.append(s1.group(0))\n",
    "                        \n",
    "                    if re.search(r'(Fax Request Sent to Server for:)', last_out2, flags= re.I):\n",
    "                        s2 = re.search(r'(Fax Request Sent to Server for:)(.*)', last_out2, flags= re.I)\n",
    "                        really_last.append(s2.group(0))\n",
    "                        \n",
    "                    if re.search(r'(Report Electronically Signed Out by)', last_out2, flags= re.I):\n",
    "                        s3 = re.search(r'(Report Electronically Signed Out by)(.*)', last_out2, flags= re.I)\n",
    "                        really_last.append(s3.group(0))\n",
    "                        \n",
    "                    if re.search(r'(EXTERNAL CC:)', last_out2, flags= re.I):\n",
    "                        s4 = re.search(r'(EXTERNAL CC:)(.*)', last_out2, flags= re.I)\n",
    "                        really_last.append(s4.group(0))\n",
    "                        \n",
    "                    if re.search(r'(\\(\\*\\*\\[MD Initials\\]\\) cc:)', last_out2, flags= re.I):\n",
    "                        s5 = re.search(r'(\\(\\*\\*\\[MD Initials\\]\\) cc:)(.*)', last_out2, flags= re.I)\n",
    "                        really_last.append(s5.group(0))\n",
    "                        \n",
    "                    really_last.sort(key=len, reverse=True)\n",
    "                    removey = really_last[0]\n",
    "                    last_section.append(removey + '\\n')\n",
    "                    liney3 = last_out2.replace(removey, '')\n",
    "                    final_out.append(liney3)\n",
    "                    \n",
    "                else:\n",
    "                    final_out.append(last_out2)\n",
    "                    \n",
    "\n",
    "            else:\n",
    "\n",
    "                section_next_title = re.sub(r'\\n|\\r', '', listy2[x2])\n",
    "                section_next_title_new = ('\\n===SECTION: %s===\\n' % (section_next_title))\n",
    "                final_out.append(section_next_title_new)\n",
    "                section_next = restringy[listy1[x2]:listy1[x2+1]]\n",
    "                #######DELETE##########\n",
    "                document_name = (doc + '\\n')\n",
    "                last_section.append(document_name)\n",
    "                lasty = []\n",
    "                #######DELETE##########\n",
    "                for liney0 in section_next:\n",
    "                    liney = liney0.lstrip()\n",
    "                    liney1 = liney.replace(section_next_title, '')\n",
    "                    liney2 = liney1.lstrip()\n",
    "                    if liney2 != '':\n",
    "                        liney2 = re.sub(r'\\n|\\r', ' ', liney2)\n",
    "                        liney2 = re.sub(r\"\\s{2,}\", \" \", liney2)\n",
    "                        ###########final_out.append(liney2)\n",
    "                        lasty.append(liney2)\n",
    "                        \n",
    "                last_out = ' '.join(lasty)\n",
    "                last_out2 = re.sub(r\"\\s{2,}\", \" \", last_out)\n",
    "                if re.search(r'(DICT:)(.*)', last_out2, flags= re.I):\n",
    "                    s = re.search(r'(DICT:)(.*)', last_out2, flags= re.I)\n",
    "                    last_section.append(s.group(0) + '\\n')\n",
    "                    liney3 = last_out2.replace(s.group(0), '')\n",
    "                    final_out.append(liney3)\n",
    "                    #line = line.replace(s.group(0), '')\n",
    "                else:\n",
    "                    final_out.append(last_out2)\n",
    "                    \n",
    "\n",
    "\n",
    "        file_save(final_out,outfile)\n",
    "        #for future_line in final_out:\n",
    "            #if re.search(r'===SECTION:', future_line):\n",
    "                #pass\n",
    "            #else:\n",
    "                #token_dictionary(future_line)\n",
    "                \n",
    "        #document_name = (doc + '\\n')\n",
    "        #first_section.append(doc)\n",
    "        #first_section.append(final_out[0])\n",
    "        \n",
    "        #for last_line in final_out:\n",
    "            #if re.search(r'(DICT:)(.*)', last_line, flags= re.I):\n",
    "                #s = re.search(r'(DICT:)(.*)', last_line, flags= re.I)\n",
    "                #last_section.append(s.group(0))\n",
    "                #line = line.replace(s.group(0), '')\n",
    "        \n",
    "        #print(final_out)\n",
    "        x1 = x1 + 1\n",
    "\n",
    "print('cases_processed')\n",
    "\n",
    "john2 = sorted(my_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "with open(dictionary_file, encoding='utf-8', mode='w') as dict_file:\n",
    "    writer = csv.writer(dict_file)\n",
    "    writer.writerows(john2)\n",
    "\n",
    "print('dictionary_completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_list = ['wo_meta_data']\n",
    "output = 'sect_sent_list'\n",
    "\n",
    "my_dict = dict()\n",
    "\n",
    "for directory in dir_list:\n",
    "    source_dir = (\"%s/%s\" % (root_dir, directory))\n",
    "    process_dir = (\"%s/%s\" % (out_dir, output))\n",
    "\n",
    "    docset = listdir(source_dir)\n",
    "    \n",
    "    print('Current Directory: %s processing.......' % directory)\n",
    "\n",
    "    x1 = 0\n",
    "    while x1 < len(docset):\n",
    "        doc = docset[x1]\n",
    "        infile = (\"%s/%s\" % (source_dir, doc))\n",
    "        outfile = (\"%s/%s\" % (process_dir, doc))\n",
    "        data = codecs.open(infile, 'r', encoding='utf-8')\n",
    "        stringy = data.readlines()\n",
    "        data.close()\n",
    "        \n",
    "        final_out = []\n",
    "        for line in (stringy):\n",
    "            if re.search(r'===SECTION:', line):\n",
    "                line = line.lstrip()\n",
    "                section = ('%s' % line)\n",
    "                final_out.append(section)\n",
    "            else:\n",
    "                line = re.sub(r'(\\s)([0-9]\\))(\\s*.*?)', '\\n\\t\\\\2', line)\n",
    "                line = re.sub(r'([a-z]\\.)(\\s*)([A-Z])', '\\\\1 |.| \\\\3', line)\n",
    "                line = re.sub(r'([A-Z]\\.)(\\s*)([A-Z])', '\\\\1 |.| \\\\3', line)\n",
    "                line = re.sub(r'([0-9]\\.)(\\s*)([A-Z])', '\\\\1 |.| \\\\3', line)\n",
    "                line = re.sub(r'([0-9]\\.)(\\s)([0-9])', '\\\\1 |.| \\\\3', line)\n",
    "                line = re.sub(r'(\\)\\.)(\\s*)([A-Z])', '\\\\1 |.| \\\\3', line)\n",
    "                line = re.sub(r'([a-z]\\.)(\\s*)([0-9])', '\\\\1 |.| \\\\3', line)\n",
    "                line = re.sub(r'(%\\.)(\\s*)([0-9])', '\\\\1 |.| \\\\3', line)\n",
    "                line2 = line.split('|.|')\n",
    "                for item in line2:\n",
    "                    item = re.sub(r'\\r|\\n|\\t', '', item)\n",
    "                    item = item.lstrip()\n",
    "                    if len(item.strip()) != 0:\n",
    "                        #print('NEW: %d::%s' % (len(item.strip()),item.strip()))\n",
    "                        final_out.append('\\t' + item.strip() + '\\n')\n",
    "                        token_dictionary(item.strip())\n",
    "\n",
    "        file_save(final_out,outfile)\n",
    "        #print(final_out)\n",
    "        x1 = x1 + 1\n",
    "\n",
    "print('cases_processed')\n",
    "\n",
    "john2 = sorted(my_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "with open(dictionary_file, encoding='utf-8', mode='w') as dict_file:\n",
    "    writer = csv.writer(dict_file)\n",
    "    writer.writerows(john2)\n",
    "\n",
    "print('dictionary_completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "TEXT_PATH_CLINICAL_HISTORY\n",
    "TEXT_PATH_COMMENTS\n",
    "TEXT_PATH_FORMAL_DX\n",
    "TEXT_PATH_FULL_TEXT\n",
    "TEXT_PATH_GROSS_PATHOLOGY\n",
    "TEXT_PATH_MICROSCOPIC_DESC\n",
    "TEXT_PATH_NATURE_OF_SPECIMENS\n",
    "TEXT_PATH_STAGING_PARAMS\n",
    "TEXT_PATH_SUPP_REPORTS_ADDENDA\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = rows_data[0]\n",
    "\n",
    "add_id1 = row[0]\n",
    "stie_id1 = row[2]\n",
    "pt_id1 = row[4]\n",
    "clin_hx1 = row[7]\n",
    "comment1 = row[8]\n",
    "form_dx1 = row[9]\n",
    "full_text1 = row[10]\n",
    "path1 = row[11]\n",
    "micro1 = row[12]\n",
    "spec1 = row[13]\n",
    "staging1 = row[14]\n",
    "adden1 = row[15]\n",
    "\n",
    "x1 = 1\n",
    "while x1 < len(rows_data):\n",
    "    \n",
    "    new_file_list = []\n",
    "    \n",
    "    row = rows_data[x1]\n",
    "    \n",
    "    add_id = row[0]\n",
    "    stie_id = row[2]\n",
    "    pt_id = row[4]\n",
    "    clin_hx = row[7]\n",
    "    comment = row[8]\n",
    "    form_dx = row[9]\n",
    "    full_text = row[10]\n",
    "    path = row[11]\n",
    "    micro = row[12]\n",
    "    spec = row[13]\n",
    "    staging = row[14]\n",
    "    adden = row[15]\n",
    "        \n",
    "    Patient_id = (\"Patient_ID : %s\" % pt_id)\n",
    "    new_file_list.append([Patient_id])\n",
    "    Label_id = (\"Label_ID : %s\" % stie_id)\n",
    "    new_file_list.append([Label_id])\n",
    "    \n",
    "    #new_file_list.append([add_id1])\n",
    "    #new_file_list.append([add_id])\n",
    "    #new_file_list.append([stie_id1])\n",
    "    #new_file_list.append([stie_id])\n",
    "    #new_file_list.append([pt_id1])\n",
    "    #new_file_list.append([pt_id])\n",
    "    new_file_list.append([clin_hx1])\n",
    "    new_file_list.append([clin_hx])\n",
    "    new_file_list.append([comment1])\n",
    "    new_file_list.append([comment])\n",
    "    new_file_list.append([form_dx1])\n",
    "    new_file_list.append([form_dx])\n",
    "    new_file_list.append([full_text1])\n",
    "    new_file_list.append([full_text])\n",
    "    new_file_list.append([path1])\n",
    "    new_file_list.append([path])\n",
    "    new_file_list.append([micro1])\n",
    "    new_file_list.append([micro])\n",
    "    new_file_list.append([spec1])\n",
    "    new_file_list.append([spec])\n",
    "    new_file_list.append([staging1])\n",
    "    new_file_list.append([staging])\n",
    "    new_file_list.append([adden1])\n",
    "    new_file_list.append([adden])\n",
    "    \n",
    "    \n",
    "    file_id = (pt_id + \"_\" + add_id)\n",
    "    path_to_data_directory = (\"/Users/patrickmcneillie/data_hub/naccr/text_files\")\n",
    "    new_file_name = (\"%s/%s.txt\" % (path_to_data_directory, file_id))\n",
    "    \n",
    "    save_text_file(new_file_list, new_file_name)\n",
    "    \n",
    "\n",
    "    x1 = x1 + 1\n",
    "\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inscope_headers_clean = []\n",
    "for item in inscope_headers:\n",
    "    if 'TEXT_PATH_' in item:\n",
    "        item = re.sub(r'TEXT_PATH_', '', item)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    inscope_headers_clean.append(item)\n",
    "\n",
    "row = rows_data[0]\n",
    "\n",
    "add_id1 = row[0]\n",
    "stie_id1 = row[2]\n",
    "pt_id1 = row[4]\n",
    "clin_hx1 = row[7]\n",
    "comment1 = row[8]\n",
    "form_dx1 = row[9]\n",
    "full_text1 = row[10]\n",
    "path1 = row[11]\n",
    "micro1 = row[12]\n",
    "spec1 = row[13]\n",
    "staging1 = row[14]\n",
    "adden1 = row[15]\n",
    "\n",
    "x1 = 1\n",
    "while x1 < len(rows_data):\n",
    "    \n",
    "    new_file_list = []\n",
    "    \n",
    "    row = rows_data[x1]\n",
    "    \n",
    "    add_id = row[0]\n",
    "    stie_id = row[2]\n",
    "    pt_id = row[4]\n",
    "    clin_hx = row[7]\n",
    "    comment = row[8]\n",
    "    form_dx = row[9]\n",
    "    full_text = row[10]\n",
    "    path = row[11]\n",
    "    micro = row[12]\n",
    "    spec = row[13]\n",
    "    staging = row[14]\n",
    "    adden = row[15]\n",
    "        \n",
    "    Patient_id = (\"Patient_ID : %s\" % pt_id)\n",
    "    new_file_list.append(Patient_id)\n",
    "    Label_id = (\"Label_ID : %s\" % stie_id)\n",
    "    new_file_list.append(Label_id)\n",
    "    \n",
    "    #new_file_list.append([add_id1])\n",
    "    #new_file_list.append([add_id])\n",
    "    #new_file_list.append([stie_id1])\n",
    "    #new_file_list.append([stie_id])\n",
    "    #new_file_list.append([pt_id1])\n",
    "    #new_file_list.append([pt_id])\n",
    "    new_file_list.append(clin_hx1)\n",
    "    new_file_list.append(clin_hx)\n",
    "    new_file_list.append(comment1)\n",
    "    new_file_list.append(comment)\n",
    "    new_file_list.append(form_dx1)\n",
    "    new_file_list.append(form_dx)\n",
    "    new_file_list.append(full_text1)\n",
    "    new_file_list.append(full_text)\n",
    "    new_file_list.append(path1)\n",
    "    new_file_list.append(path)\n",
    "    new_file_list.append(micro1)\n",
    "    new_file_list.append(micro)\n",
    "    new_file_list.append(spec1)\n",
    "    new_file_list.append(spec)\n",
    "    new_file_list.append(staging1)\n",
    "    new_file_list.append(staging)\n",
    "    new_file_list.append(adden1)\n",
    "    new_file_list.append(adden)\n",
    "    \n",
    "    \n",
    "    file_id = (pt_id + \"_\" + add_id)\n",
    "    path_to_data_directory = (\"/Users/patrickmcneillie/data_hub/naccr/text_files_v2\")\n",
    "    new_file_name = (\"%s/%s.txt\" % (path_to_data_directory, file_id))\n",
    "    \n",
    "    save_text_file(new_file_list, new_file_name)\n",
    "    \n",
    "\n",
    "    x1 = x1 + 1\n",
    "\n",
    "print('complete')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
