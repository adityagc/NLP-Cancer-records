{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Good_words_final_final.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-23f925b77381>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Data-clean/concatenated_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Good_words_final_final.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mclassmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'BREAST'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'COLON'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'LUNG'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'OTHER'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'PROSTATE'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding)\u001b[0m\n\u001b[1;32m   1687\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1688\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1689\u001b[0;31m             \u001b[0mfhd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1690\u001b[0m             \u001b[0mown_fhd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    614\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    615\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Good_words_final_final.txt not found."
     ]
    }
   ],
   "source": [
    "new = pd.read_csv('../Data-clean/concatenated_data.csv')\n",
    "vocab = list(set(np.genfromtxt('Good_words_final_final.txt',dtype=str,delimiter=',')))\n",
    "classmap={0:'BREAST',1:'COLON',2:'LUNG',3:'OTHER',4:'PROSTATE'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(new['Text'], new['SITE'], random_state = 137)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df = 3,ngram_range= (1,1), stop_words = 'english',vocabulary=vocab).fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_test_vectorized = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive_Bayes\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "clfrNB = naive_bayes.MultinomialNB(alpha=0.00001)\n",
    "clfrNB.fit(X_train_vectorized,y_train)\n",
    "\n",
    "predictedNB= clfrNB.predict(X_test_vectorized)\n",
    "probNB=clfrNB.predict_proba(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracyNB = clfrNB.score(X_train_vectorized, y_train)\n",
    "test_accuracyNB = clfrNB.score(X_test_vectorized, y_test)\n",
    "\n",
    "# print(\"Accuracy on training data: %0.2f\" %(training_accuracy))\n",
    "# print(\"Accuracy on test data: %0.2f\" %(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log Reg\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log = LogisticRegression(penalty='l2',C=0.001)\n",
    "log.fit(X_train_vectorized,y_train)\n",
    "\n",
    "predictedlog = log.predict(X_test_vectorized)\n",
    "problog=log.predict_proba(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracyLR = log.score(X_train_vectorized, y_train)\n",
    "test_accuracyLR = log.score(X_test_vectorized, y_test)\n",
    "\n",
    "# print(\"Accuracy on training data: %0.2f\" %(training_accuracy))\n",
    "# print(\"Accuracy on test data: %0.2f\" %(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "from sklearn import svm\n",
    "\n",
    "clfrSVM = svm.SVC(kernel = 'rbf', C = 1,probability=True)\n",
    "clfrSVM.fit(X_train_vectorized, y_train)\n",
    "\n",
    "predictedsvm = clfrSVM.predict(X_test_vectorized)\n",
    "probsvm = clfrSVM.predict_proba(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracySVM = clfrSVM.score(X_train_vectorized, y_train)\n",
    "test_accuracySVM = clfrSVM.score(X_test_vectorized, y_test)\n",
    "\n",
    "# print(\"Accuracy on training data: %0.2f\" %(training_accuracy))\n",
    "# print(\"Accuracy on test data: %0.2f\" %(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "\n",
    "clfrknn = knn(n_neighbors=8,algorithm='auto')\n",
    "clfrknn.fit(X_train_vectorized,y_train)\n",
    "\n",
    "predictedknn = clfrknn.predict(X_test_vectorized)\n",
    "probknn = clfrknn.predict_proba(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracyKNN = clfrknn.score(X_train_vectorized, y_train)\n",
    "test_accuracyKNN = clfrknn.score(X_test_vectorized, y_test)\n",
    "\n",
    "# print(\"Accuracy on training data: %0.2f\" %(training_accuracy))\n",
    "# print(\"Accuracy on test data: %0.2f\" %(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "\n",
    "clfrrf = rf(n_estimators=2)\n",
    "clfrrf.fit(X_train_vectorized,y_train)\n",
    "\n",
    "predictedrf = clfrrf.predict(X_test_vectorized)\n",
    "probrf = clfrrf.predict_proba(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracyRF = clfrrf.score(X_train_vectorized, y_train)\n",
    "test_accuracyRF = clfrrf.score(X_test_vectorized, y_test)\n",
    "\n",
    "# print(\"Accuracy on training data: %0.2f\" %(training_accuracy))\n",
    "# print(\"Accuracy on test data: %0.2f\" %(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.argmax(probNB,axis=1)\n",
    "b=np.argmax(problog,axis=1)\n",
    "c=np.argmax(probsvm,axis=1)\n",
    "d=np.argmax(probknn,axis=1)\n",
    "e=np.argmax(probrf,axis=1)\n",
    "\n",
    "combine= np.array((a,b,c,d,e)).T # 94.04\n",
    "combine= np.array((a,b,d)).T #93.33\n",
    "combine= np.array((a,c,e)).T #93.33\n",
    "combine= np.array((a,d,e)).T #93.66\n",
    "combine= np.array((a,b,c,d)).T #94.72\n",
    "combine= np.array((b,c,d,e)).T #95.07\n",
    "#combine= np.array((c,d,e)).T #93.33\n",
    "#combine= np.array((b,d,e)).T #94.04\n",
    "#combine= np.array((b,c,d)).T #95.07\n",
    "combine= np.array((a,a,b)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predind = []\n",
    "for i in range(len(combine)):\n",
    "    a=list(combine[i,:]).count(0)\n",
    "    b=list(combine[i,:]).count(1)\n",
    "    c=list(combine[i,:]).count(2)\n",
    "    d=list(combine[i,:]).count(3)\n",
    "    e=list(combine[i,:]).count(4)\n",
    "    predind.append(np.argmax(np.array([a,b,c,d,e])))\n",
    "    \n",
    "predmod = [classmap[i] for i in predind]\n",
    "np.mean(predmod==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify=pd.DataFrame()\n",
    "# classify['PatientID'] = [list(new['PATIENT_DISPLAY_ID'])[i] for i in X_test.index.tolist()] \n",
    "# classify['Y_test'] = y_test.values\n",
    "# classify['NB'] = predictedNB\n",
    "# classify['Log reg'] = predictedlog\n",
    "# classify['SVM'] = predictedsvm\n",
    "# classify['knn'] = predictedknn\n",
    "# classify['RF'] = predictedrf\n",
    "# classify['Final'] = predmod\n",
    "# classify.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from numpy import loadtxt, mean\n",
    "\n",
    "def f1(predmod):\n",
    "    test_data = y_test.values\n",
    "    predicted = np.array(predmod)\n",
    "    class_labels = ['BREAST','COLON','LUNG','OTHER','PROSTATE']\n",
    "\n",
    "    precision, recall, fscore, class_count = score(test_data, predicted, labels=class_labels)\n",
    "\n",
    "#     for i in range(5):\n",
    "#         print (class_labels[i])\n",
    "#         print ('\\tprecision: ' + '{0:.5f}'.format(precision[i]))\n",
    "#         print ('\\trecall: ' + '{0:.5f}'.format(recall[i]))\n",
    "#         print ('\\tfscore: ' + '{0:.5f}'.format(fscore[i]))\n",
    "\n",
    "    #print ('\\nF1 MACRO: {0:.5f}'.format(mean(fscore)))\n",
    "    return (mean(fscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ=pd.DataFrame()\n",
    "summ['Classifier'] = ['NB','LR','SVM','KNN','RF']\n",
    "summ.set_index(summ.Classifier)\n",
    "summ['Training_Accu'] = [training_accuracyNB,training_accuracyLR,training_accuracySVM,training_accuracyKNN,training_accuracyRF]\n",
    "summ['Testing_Accu'] = [test_accuracyNB,test_accuracyLR,test_accuracySVM,test_accuracyKNN,test_accuracyRF]\n",
    "summ['F1_score'] = [f1(predictedNB),f1(predictedlog),f1(predictedsvm),f1(predictedknn),f1(predictedrf)]\n",
    "print ('Ensemble accuracy = ',np.mean(predmod==y_test))\n",
    "print ('Ensemble f1 =',f1(predmod))\n",
    "summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame()\n",
    "# df['Patient ID'] = classify['PatientID']\n",
    "# df['Site'] = predictedNB\n",
    "# df['Confidence'] = list(np.max(probNB,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def color_negative_red(val):\n",
    "#     \"\"\"\n",
    "#     Takes a scalar and returns a string with\n",
    "#     the css property `'color: red'` for negative\n",
    "#     strings, black otherwise.\n",
    "#     \"\"\"\n",
    "#     color = 'red' if val < 0.9 else 'black'\n",
    "#     return 'color: %s' % color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def highlight_max(s):\n",
    "#     '''\n",
    "#     highlight the maximum in a Series yellow.\n",
    "#     '''\n",
    "    \n",
    "#     return ['background-color: yellow' if v else '' for v in is_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newdf = pd.DataFrame()\n",
    "# newdf['Confidence'] = df['Confidence'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = newdf.style.apply(color_negative_red,subset=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Confidence'] =s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive_Bayes\n",
    "output_tr=[]\n",
    "output_te=[]\n",
    "alpha_list=[0,0.00001,0.0001]\n",
    "for alpha in alpha_list:\n",
    "    clfrNB = naive_bayes.MultinomialNB(alpha=alpha)\n",
    "    clfrNB.fit(X_train_vectorized,y_train)\n",
    "\n",
    "    predictedNB= clfrNB.predict(X_test_vectorized)\n",
    "    probNB=clfrNB.predict_proba(X_test_vectorized)\n",
    "\n",
    "    training_accuracyNB = clfrNB.score(X_train_vectorized, y_train)\n",
    "    test_accuracyNB = clfrNB.score(X_test_vectorized, y_test)\n",
    "    \n",
    "    output_tr.append(training_accuracyNB)\n",
    "    output_te.append(test_accuracyNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(alpha_list,output_tr)\n",
    "plt.plot(alpha_list,output_te)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
